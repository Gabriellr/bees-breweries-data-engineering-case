from mage_ai.settings.repo import get_repo_path
from mage_ai.io.config import ConfigFileLoader
from mage_ai.io.s3 import S3
from os import path
from pyspark.sql import SparkSession
import tempfile
import os

if 'data_loader' not in globals():
    from mage_ai.data_preparation.decorators import data_loader
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test

@data_loader
def load_from_s3_bucket(*args, **kwargs):
    """
    Carrega um arquivo JSON do S3 e o lê como Spark DataFrame.
    """

    # Parâmetros
    config_path = path.join(get_repo_path(), 'io_config.yaml')
    config_profile = 'default'
    bucket_name = 'db-inbev-bronze-layer'
    object_key = 'breweries_raw.json'

    # Baixa o arquivo temporariamente
    s3 = S3.with_config(ConfigFileLoader(config_path, config_profile))
    file_data = s3.load(bucket_name, object_key)

    with tempfile.NamedTemporaryFile(delete=False, suffix='.json') as tmp_file:
        tmp_file.write(file_data.encode('utf-8'))
        tmp_file_path = tmp_file.name

    # Cria sessão Spark
    spark = SparkSession.builder \
        .appName("Load JSON from S3 with Spark") \
        .getOrCreate()

    # Lê com Spark
    df = spark.read.json(tmp_file_path)

    # Opcional: remove o arquivo temporário
    os.remove(tmp_file_path)

    return df


@test
def test_output(output, *args) -> None:
    """
    Testa se o DataFrame Spark foi carregado corretamente.
    """
    assert output is not None, 'O DataFrame está vazio'
    assert output.count() > 0, 'O DataFrame não contém linhas'