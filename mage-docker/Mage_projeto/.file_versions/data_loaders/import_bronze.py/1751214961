from os import path
from mage_ai.settings.repo import get_repo_path
from pyspark.sql import SparkSession

if 'data_loader' not in globals():
    from mage_ai.data_preparation.decorators import data_loader
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test


@data_loader
def load_from_s3_bucket(*args, **kwargs):
    """
    Lê arquivo JSON de um bucket S3 usando Spark.
    Certifique-se de que o Spark está configurado para acessar o S3 via s3a://
    """

    # Inicializa sessão Spark
    spark = SparkSession.builder \
        .appName("LoadFromS3") \
        .getOrCreate()

    # Nome do bucket e caminho do arquivo
    bucket_name = 'db-inbev-bronze-layer'
    object_key = 'breweries_raw.json'
    s3_path = f's3a://{bucket_name}/{object_key}'

    # Leitura do JSON via Spark
    df = spark.read.json(s3_path)

    return df


@test
def test_output(output, *args) -> None:
    """
    Testa se a saída não está vazia.
    """
    assert output is not None, 'O DataFrame está indefinido'
    assert output.count() > 0, 'O DataFrame está vazio'
