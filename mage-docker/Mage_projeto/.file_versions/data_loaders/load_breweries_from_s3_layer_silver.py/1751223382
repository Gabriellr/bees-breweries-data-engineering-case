from mage_ai.settings.repo import get_repo_path
from mage_ai.io.config import ConfigFileLoader
from mage_ai.io.s3 import S3
from os import path
import boto3
import pandas as pd
from datetime import datetime

if 'data_loader' not in globals():
    from mage_ai.data_preparation.decorators import data_loader
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test


@data_loader
def load_from_s3_bucket(*args, **kwargs):
    """
    Lê todos arquivos .parquet de um bucket S3, incluindo subpastas,
    e concatena os DataFrames usando boto3 + Mage S3 loader.
    Verifica se o arquivo _SUCCESS existe antes de carregar os dados.
    """
    config_path = path.join(get_repo_path(), 'io_config.yaml')
    config_profile = 'default'

    bucket_name = 'db-inbev-silver-layer'

    # Define prefixo com a data atual, ex: breweries_raw/2025-06-29
    folder_name = datetime.today().strftime('%Y-%m-%d')
    s3_prefix = f"breweries_raw/{folder_name}/"

    # Inicializa boto3 para listar arquivos
    s3_client = boto3.client('s3')

    # Verifica se arquivo _SUCCESS existe
    success_key = s3_prefix + '_SUCCESS'

    try:
        response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=success_key)
        success_exists = 'Contents' in response and any(obj['Key'] == success_key for obj in response['Contents'])
    except Exception as e:
        raise RuntimeError(f"Erro ao verificar arquivo _SUCCESS no bucket: {str(e)}")

    if not success_exists:
        raise FileNotFoundError(f"Arquivo _SUCCESS não encontrado em s3://{bucket_name}/{success_key}")

    # Lista arquivos .parquet
    paginator = s3_client.get_paginator('list_objects_v2')
    pages = paginator.paginate(Bucket=bucket_name, Prefix=s3_prefix)

    object_keys = []
    for page in pages:
        for obj in page.get('Contents', []):
            key = obj['Key']
            if key.endswith('.parquet'):
                object_keys.append(key)

    if not object_keys:
        raise Exception(f"Nenhum arquivo .parquet encontrado em s3://{bucket_name}/{s3_prefix}")

    print(f" {len(object_keys)} arquivos encontrados para carregar...")

    # Carrega todos os arquivos usando Mage S3
    dfs = []
    for key in object_keys:
        print(f" Lendo: {key}")
        df = S3.with_config(ConfigFileLoader(config_path, config_profile)).load(bucket_name, key)
        dfs.append(df)

    return pd.concat(dfs, ignore_index=True)


@test
def test_output(output, *args) -> None:
    assert output is not None, ' Nenhum dado carregado.'
    print(f" DataFrame final com {len(output)} registros.")
