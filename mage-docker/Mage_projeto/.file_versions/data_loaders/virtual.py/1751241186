from mage_ai.data_preparation.decorators import data_loader
from pyspark.sql import SparkSession
import logging

@data_loader
def load_virtualized_parquet(*args, **kwargs):
    """
    Cria uma view tempor√°ria no Spark com base em arquivos Parquet no S3.
    Permite que os dados sejam consultados via Spark SQL como uma tabela virtual.
    """

    # Par√¢metros
    bucket_name = 'db-inbev-gold-layer'
    prefix = kwargs.get('folder_name', '')  # Ex: '2025-06-29/' ou subdiret√≥rios
    s3_path = f"s3a://{bucket_name}/{prefix}*"

    logging.info(f"üì• Virtualizando Parquet em: {s3_path}")

    # Inicia sess√£o Spark
    spark = SparkSession.builder.appName("VirtualizeParquet").getOrCreate()

    # Cria DataFrame do Parquet (sem mover dados) e cria uma view tempor√°ria
    df = spark.read.parquet(s3_path)
    df.createOrReplaceTempView("breweries_virtual_view")

    logging.info("‚úÖ View tempor√°ria criada: breweries_virtual_view")

    return df  # Tamb√©m retorna o DataFrame para transforma√ß√£o posterior
