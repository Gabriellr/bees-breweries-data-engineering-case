from mage_ai.settings.repo import get_repo_path
from mage_ai.io.config import ConfigFileLoader
from mage_ai.io.s3 import S3
from os import path
import boto3
import pandas as pd

if 'data_loader' not in globals():
    from mage_ai.data_preparation.decorators import data_loader
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test


@data_loader
def load_from_s3_bucket(*args, **kwargs):
    """
    Lê todos arquivos .parquet de um bucket S3, incluindo subpastas,
    e concatena os DataFrames usando boto3 + Mage S3 loader.
    """
    config_path = path.join(get_repo_path(), 'io_config.yaml')
    config_profile = 'default'

    bucket_name = 'db-inbev-silver-layer'
    prefix = kwargs.get('breweries_raw', '')  # Ex: '2025-06-29/' ou ''

    # Inicializa boto3 para listar arquivos
    s3_client = boto3.client('s3')
    paginator = s3_client.get_paginator('list_objects_v2')
    pages = paginator.paginate(Bucket=bucket_name, Prefix=prefix)

    object_keys = []
    for page in pages:
        for obj in page.get('Contents', []):
            key = obj['Key']
            if key.endswith('.parquet'):
                object_keys.append(key)

    if not object_keys:
        raise Exception(f"Nenhum arquivo .parquet encontrado em s3://{bucket_name}/{prefix}")

    print(f"🔍 {len(object_keys)} arquivos encontrados para carregar...")

    # Carrega todos os arquivos usando Mage S3
    dfs = []
    for key in object_keys:
        print(f"📥 Lendo: {key}")
        df = S3.with_config(ConfigFileLoader(config_path, config_profile)).load(bucket_name, key)
        dfs.append(df)

    return pd.concat(dfs, ignore_index=True)


@test
def test_output(output, *args) -> None:
    assert output is not None, '❌ Nenhum dado carregado.'
    print(f"✅ DataFrame final com {len(output)} registros.")