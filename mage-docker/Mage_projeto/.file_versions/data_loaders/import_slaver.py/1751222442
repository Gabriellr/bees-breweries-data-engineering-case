from mage_ai.settings.repo import get_repo_path
from mage_ai.io.config import ConfigFileLoader
from os import path
from pyspark.sql import SparkSession

if 'data_loader' not in globals():
    from mage_ai.data_preparation.decorators import data_loader
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test


@data_loader
def load_from_s3_bucket(*args, **kwargs):
    """
    Lê arquivos .parquet de um bucket S3 usando Spark,
    sem verificar o arquivo _SUCCESS.
    """
    config_path = path.join(get_repo_path(), 'io_config.yaml')
    config_profile = 'default'

    bucket_name = 'db-inbev-silver-layer'
    prefix = kwargs.get('prefix', 'breweries_raw/2025-06-29/')  # Exemplo padrão

    # Inicializa SparkSession
    spark = SparkSession.builder.getOrCreate()

    # Define o caminho completo no S3 para os arquivos parquet
    s3_path = f"s3a://{bucket_name}/{prefix}"

    # Lê todos arquivos parquet do prefixo com Spark
    df = spark.read.parquet(s3_path)

    return df


@test
def test_output(output, *args) -> None:
    assert output is not None and output.count() > 0, 'O DataFrame Spark está vazio'
    print(f"✅ DataFrame carregado com {output.count()} registros.")
