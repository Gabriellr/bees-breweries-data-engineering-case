## BEES Data Engineering ‚Äì Breweries Case

Este pipeline de dados, desenvolvido em Docker, realiza a extra√ß√£o de informa√ß√µes da API Open Brewery DB. Utilizando Apache Spark para processamento e transforma√ß√£o, e Mage.ai para orquestra√ß√£o, ele aplica a arquitetura Medallion para estruturar os dados em tr√™s camadas.

Os dados s√£o armazenados em um Data Lake na nuvem (AWS S3 ). Na camada Bronze, os dados brutos da API s√£o salvos em formato Parquet; na camada Silver, s√£o transformados e particionados por localiza√ß√£o; e na camada Gold, os dados s√£o agregados e enriquecidos com m√©tricas como o n√∫mero de cervejarias por tipo e regi√£o.

# Tecnologias e Ferramentas

- **Mage.ai** ‚Äì Orquestra√ß√£o do pipeline  
- **PySpark** ‚Äì Processamento distribu√≠do  
- **Pandas** ‚Äì Manipula√ß√£o de dados leves  
- **AWS S3** ‚Äì Camadas do data lake  
- **boto3** ‚Äì Integra√ß√£o program√°tica com S3  
- **Docker** ‚Äì Containeriza√ß√£o do ambiente  
    
 ##  Arquitetura de Pipeline

O pipeline foi desenvolvido com base na arquitetura **Medallion**, utilizando tecnologias modernas, escal√°veis e com foco em boas pr√°ticas de engenharia de dados.

###  Estrutura em Camadas (Medallion)

A arquitetura organiza os dados em tr√™s camadas principais:

- **üîπ Bronze (Raw)**  
  Armazena os dados brutos coletados diretamente da API, sem transforma√ß√µes. Serve como fonte de verdade imut√°vel.

- **üî∏ Silver (Curated)**  
  Realiza a limpeza, normaliza√ß√£o e enriquecimento dos dados. Salva em formato colunar (Parquet), particionado por pa√≠s e regi√£o.

- **ü•á Gold (Analytics)**  
  Dados prontos para consumo anal√≠tico. Aqui, s√£o geradas **agrega√ß√µes por tipo de cervejaria e localiza√ß√£o**, otimizando performance para dashboards e relat√≥rios.

![bees-brew drawio](https://github.com/user-attachments/assets/30379ef6-8a66-4e1f-bc69-9505c81358cc)

## Instala√ß√£o

### Pr√©-requisitos

- Docker instalado na sua m√°quina (vers√£o recomendada >= 20.x)

### Passos para rodar o projeto

### Passos para rodar o projeto

1. **Clone o reposit√≥rio**

   Clone este projeto em sua m√°quina local:

   ```bash
   git clone https://github.com/Gabriellr/bees-breweries-data-engineering-case.git
   cd bees-breweries-data-engineering-case

2. **Instale e inicie o Docker**
   Certifique-se de que o Docker Desktop est√° instalado e em execu√ß√£o na sua m√°quina.
Com o Docker pronto, navegue at√© a raiz do projeto mage-docker e execute o seguinte comando para iniciar o Mage.ai:

   ```bash
   docker-compose up --build

 2. **Executando o Pipeline pela Interface do Mage.ai**

Para executar manualmente seu pipeline no Mage.ai, siga os passos abaixo:

1. Acesse a interface web em: [http://localhost:6789](http://localhost:6789) ou [http://localhost:6789/pipelines/elt_proj_breweries/triggers](http://localhost:6789/pipelines/elt_proj_breweries/triggers) 

2. No menu lateral, clique na aba **Pipelines**.

3. Selecione o pipeline desejado (por exemplo: `elt_proj_breweries`).

4. Na p√°gina do pipeline, v√° at√© a aba **Triggers**.

5. Clique no bot√£o **`Run@once`** para iniciar a execu√ß√£o manual do pipeline.

![mageai_run](https://github.com/user-attachments/assets/9360bb6b-a802-41e6-8875-d8119212d7dc)

Voc√™ poder√° **acompanhar o progresso**, **verificar os logs** e **analisar os resultados em tempo real** diretamente pela interface gr√°fica.

---
